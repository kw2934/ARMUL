{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843be39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper: Duan and Wang. \"Adaptive and Robust Multi-Task Learning.\" arXiv preprint arXiv:2202.05250 (2022).\n",
    "\n",
    "# Multi-task logistic regression by ARMUL and baseline procedures\n",
    "# Real dataset: Human activity recognition [Anguita et al. \"A public domain dataset for human activity recognition using smartphones.\" Proceedings of the 21th international European symposium on artificial neural networks, computational intelligence and machine learning. (2013)]\n",
    "# 30 volunteers (tasks), 225 - 328 samples for each;\n",
    "# 561 features with time and frequency domain variables;\n",
    "# 6 activities: walking, walking-upstairs, walking-downstairs, sitting, standing, laying.\n",
    "\n",
    "# Preprocessing:\n",
    "# Hold out 20% of data from each task for testing;\n",
    "# Reduce the dimension to 100 by PCA;\n",
    "# Convert to binary classification with 2 classes: sitting vs. others.\n",
    "\n",
    "# Evaluation metric: average misclassification error over all testing data\n",
    "\n",
    "# Setup\n",
    "import numpy as np\n",
    "from ARMUL import ARMUL, Baselines\n",
    "from preprocessing import load, split\n",
    "\n",
    "m = 30 # number of tasks\n",
    "prop = 0.2 * np.ones(m) # hold out 20% of data from each task for testing\n",
    "eta = 0.1 # step size for the optimization algorithm (proximal gradient descent)\n",
    "T = 200 # number of iterations in optimization\n",
    "seed = 10000 # random seed\n",
    "\n",
    "[data_raw, _, _] = load(dataset = 'HAR_binary', path = '', PCs = 100) # load data\n",
    "[data_train, data_test] = split(data = data_raw, prop = prop, seed = seed) # train-test split\n",
    "d = data_train[0][0].shape[1] # dimension\n",
    "n_list = np.array( [data_train[0][j].shape[0] for j in range(m)] ) # list of sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acdb0a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla ARMUL: 0.015632633121641426\n",
      "Clustered ARMUL: 0.01172447484123107\n",
      "Low-rank ARMUL: 0.008304836345872008\n"
     ]
    }
   ],
   "source": [
    "# ARMUL\n",
    "test = ARMUL('logistic')\n",
    "\n",
    "# Example: take lambda_j = 0.1 * np.sqrt(d / n_j) for all j in [m]\n",
    "lbd = 0.1 * np.sqrt(d / n_list)\n",
    "\n",
    "# Vanilla ARMUL\n",
    "test.vanilla(data_train, lbd, eta_global = eta, eta_local = eta, T_global = T)\n",
    "test.results = test.evaluate(data_test, model = 'vanilla')\n",
    "print( 'Vanilla ARMUL: {}'.format(test.results['average error']) ) # average testing error\n",
    "\n",
    "\n",
    "# Clustered ARMUL\n",
    "K = 4 # number of clusters\n",
    "test.clustered(data_train, lbd, K = K, eta_B = eta, eta_local = eta, T_global = T)\n",
    "test.results = test.evaluate(data_test, model = 'clustered')\n",
    "print( 'Clustered ARMUL: {}'.format(test.results['average error']) )\n",
    "\n",
    "\n",
    "# Low-rank ARMUL\n",
    "K = 4 # rank\n",
    "test.lowrank(data_train, lbd, K = K, eta_B = eta, eta_Z = eta, eta_local = eta, T_global = T)\n",
    "test.results = test.evaluate(data_test, model = 'lowrank')\n",
    "print( 'Low-rank ARMUL: {}'.format(test.results['average error']) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac45da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla ARMUL\n",
      "CV errors corresponding to all C's: [0.0125908  0.01162825 0.01077827 0.01903212]\n",
      "Average testing error of the final model: 0.013190034196384953\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "C_list = [0.05, 0.1, 0.2, 0.4]\n",
    "lbd_list = [C * np.sqrt(d / n_list) for C in C_list]\n",
    "n_fold = 5 # number of folds for cross-validation\n",
    "\n",
    "\n",
    "print('Vanilla ARMUL') # Vanilla ARMUL\n",
    "test.cv(data_train, lbd_list, model = 'vanilla', n_fold = 5, seed = seed, eta_global = eta, eta_local = eta, eta_B = eta, eta_Z = eta, T_global = T)\n",
    "print( 'CV errors corresponding to all C\\'s: {}'.format(test.errors_cv) )\n",
    "test.results = test.evaluate(data_test, model = 'vanilla')\n",
    "print( 'Average testing error of the final model: {}'.format(test.results['average error']) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e475e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-task learning: 0.025403028822667317\n",
      "Data pooling: 0.03663898387884709\n",
      "Clustered MTL: 0.022960429897410845\n",
      "Low-rank MTL: 0.016609672691744015\n"
     ]
    }
   ],
   "source": [
    "# Baselines\n",
    "base = Baselines('logistic')\n",
    "\n",
    "# Single-task learning\n",
    "base.STL_train(data_train, eta = eta, T = T)\n",
    "base.results_baseline = base.evaluate(data_test, model = 'STL')\n",
    "print( 'Single-task learning: {}'.format(base.results_baseline['average error']) )\n",
    "\n",
    "\n",
    "# Data pooling\n",
    "base.DP_train(data_train, eta = eta, T = T)\n",
    "base.results_baseline = base.evaluate(data_test, model = 'DP')\n",
    "print( 'Data pooling: {}'.format(base.results_baseline['average error']) )\n",
    "\n",
    "\n",
    "# Clustered MTL\n",
    "K = 4 # number of clusters\n",
    "base.clustered_train(data_train, K = K, eta_B = eta, T = T)\n",
    "base.results_baseline = base.evaluate(data_test, model = 'clustered')\n",
    "print( 'Clustered MTL: {}'.format(base.results_baseline['average error']) )\n",
    "\n",
    "\n",
    "# Low-rank MTL\n",
    "K = 4 # rank\n",
    "base.lowrank_train(data_train, K = K, eta_B = eta, eta_Z = eta, T = T)\n",
    "base.results_baseline = base.evaluate(data_test, model = 'lowrank')\n",
    "print( 'Low-rank MTL: {}'.format(base.results_baseline['average error']) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b5bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c2e5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9ecac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-class logistic regression: direct classification of all 6 activities\n",
    "\n",
    "[data_raw, _, _] = load(dataset = 'HAR', path = '', PCs = 100) # load data\n",
    "[data_train, data_test] = split(data = data_raw, prop = prop, seed = seed) # train-test split\n",
    "d = data_train[0][0].shape[1] # dimension\n",
    "n_list = np.array( [data_train[0][j].shape[0] for j in range(m)] ) # list of sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7979b73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla ARMUL: 0.009770395701025891\n",
      "Clustered ARMUL: 0.009281875915974597\n",
      "Low-rank ARMUL: 0.006350757205666829\n"
     ]
    }
   ],
   "source": [
    "# ARMUL\n",
    "test = ARMUL('logistic', n_class = 6)\n",
    "\n",
    "# Example: take lambda_j = 0.1 * np.sqrt(d / n_j) for all j in [m]\n",
    "lbd = 0.1 * np.sqrt(d / n_list)\n",
    "\n",
    "# Vanilla ARMUL\n",
    "test.vanilla(data_train, lbd, eta_global = eta, eta_local = eta, T_global = T)\n",
    "test.results = test.evaluate(data_test, model = 'vanilla')\n",
    "print( 'Vanilla ARMUL: {}'.format(test.results['average error']) ) # average testing error\n",
    "\n",
    "\n",
    "# Clustered ARMUL\n",
    "K = 4 # number of clusters\n",
    "test.clustered(data_train, lbd, K = K, eta_B = eta, eta_local = eta, T_global = T)\n",
    "test.results = test.evaluate(data_test, model = 'clustered')\n",
    "print( 'Clustered ARMUL: {}'.format(test.results['average error']) )\n",
    "\n",
    "\n",
    "# Low-rank ARMUL\n",
    "K = 4 # rank\n",
    "test.lowrank(data_train, lbd, K = K, eta_B = eta, eta_Z = eta, eta_local = eta, T_global = T)\n",
    "test.results = test.evaluate(data_test, model = 'lowrank')\n",
    "print( 'Low-rank ARMUL: {}'.format(test.results['average error']) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf66fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla ARMUL\n",
      "CV errors corresponding to all C's: [0.00908288 0.00883736 0.00798768 0.00896062]\n",
      "Average testing error of the final model: 0.009281875915974597\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "C_list = [0.05, 0.1, 0.2, 0.4]\n",
    "lbd_list = [C * np.sqrt(d / n_list) for C in C_list]\n",
    "n_fold = 5 # number of folds for cross-validation\n",
    "\n",
    "\n",
    "print('Vanilla ARMUL') # Vanilla ARMUL\n",
    "test.cv(data_train, lbd_list, model = 'vanilla', n_fold = 5, seed = seed, eta_global = eta, eta_local = eta, eta_B = eta, eta_Z = eta, T_global = T)\n",
    "print( 'CV errors corresponding to all C\\'s: {}'.format(test.errors_cv) )\n",
    "test.results = test.evaluate(data_test, model = 'vanilla')\n",
    "print( 'Average testing error of the final model: {}'.format(test.results['average error']) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "614038cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-task learning: 0.019540791402051783\n",
      "Data pooling: 0.0356619443087445\n",
      "Clustered MTL: 0.024914509037616023\n",
      "Low-rank MTL: 0.014167073766487542\n"
     ]
    }
   ],
   "source": [
    "# Baselines\n",
    "base = Baselines('logistic', n_class = 6)\n",
    "\n",
    "# Single-task learning\n",
    "base.STL_train(data_train, eta = eta, T = T)\n",
    "base.results_baseline = base.evaluate(data_test, model = 'STL')\n",
    "print( 'Single-task learning: {}'.format(base.results_baseline['average error']) )\n",
    "\n",
    "\n",
    "# Data pooling\n",
    "base.DP_train(data_train, eta = eta, T = T)\n",
    "base.results_baseline = base.evaluate(data_test, model = 'DP')\n",
    "print( 'Data pooling: {}'.format(base.results_baseline['average error']) )\n",
    "\n",
    "\n",
    "# Clustered MTL\n",
    "K = 4 # number of clusters\n",
    "base.clustered_train(data_train, K = K, eta_B = eta, T = T)\n",
    "base.results_baseline = base.evaluate(data_test, model = 'clustered')\n",
    "print( 'Clustered MTL: {}'.format(base.results_baseline['average error']) )\n",
    "\n",
    "\n",
    "# Low-rank MTL\n",
    "K = 4 # rank\n",
    "base.lowrank_train(data_train, K = K, eta_B = eta, eta_Z = eta, T = T)\n",
    "base.results_baseline = base.evaluate(data_test, model = 'lowrank')\n",
    "print( 'Low-rank MTL: {}'.format(base.results_baseline['average error']) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ad9603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
